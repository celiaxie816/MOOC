Simple Linear Regression 

##Part 1: Predictor vs Response Variable
# The predictor variable
money <- c(1, 2, 3, 4, 5, 6, 7, 8, 9, 10)

# The response variable
liking <- c(2.2, 2.8, 4.5, 3.1, 8.7, 5.0, 4.5, 8.8, 9.0, 9.2)

# Correlation between money and liking
cxy <- cor(money, liking)

# Standard deviation of money
sx <- sd(money)

# Standard deviation of liking
sy <- sd(liking)

# Calculate the the regression slope using cxy, sx and sy
cxy * (sy / sx)

# Calculate the intercept
intercept <-mean(liking) - 0.778 * mean(money)

# Calculate the intercept and slope using lm()
lm(liking~money)

# Vector containing the amount of money you gave participants
money  <- c(1, 2, 3, 4, 5, 6, 7, 8, 9, 10)

# Vector containing the amount the participants liked you
liking <- c(2.2, 2.8, 4.5, 3.1, 8.7, 5.0, 4.5, 8.8, 9.0, 9.2)

# Calculate the R squared of our regression model using cor()
(cor(money, liking))^2

# Assign the summary of lm(liking ~ money) to 'sum'
sum <- summary(lm(liking ~ money))

nh<- "There will be no relationship between money and liking"
ah<- "More money will be related to more liking"

# Assign regression model to variable "mod1"
mod1 <- lm(liking ~ money)

# Assign the summary of 'mod1' to 'sum1'
sum1 <- summary(mod1)

#CI: teststatistic±marginoferror,  tα/2,df=n−2∗seslope
# Calculate the upper confidence interval
upper <- 0.7782 + (2.306 * 0.1847)

# Calculate the lower confidence interval
lower <- 0.7782 - (2.306 * 0.1847)

# Obtain the residuals from mod1 using $, assign to "resmod1"
resmod1 <- mod1$resid

# plot the residuals on the y-axis, and liking on the x-axis
plot(liking, resmod1)

# plot the residuals on the y-axis, and money on the x-axis
plot(money,resmod1)

# Make a histogram of your residuals
hist(resmod1)

# Value for which you would like a prediction
nd <- data.frame( money=3)

# Find the prediction interval
predict(mod1, nd, level = 0.95, interval = "predict")

# Find the confidence interval
predict(mod1, nd, level = 0.95, interval = "confidence")









